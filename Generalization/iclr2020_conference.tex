
\documentclass{article} % For LaTeX2e
\usepackage{iclr2020_conference,times}
\usepackage{graphicx}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{balance}
\usepackage{comment}
\usepackage{enumerate}
\usepackage{amssymb,amsmath}
\usepackage{afterpage}
\usepackage{url}
\usepackage{xspace}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{booktabs}
\usepackage{float}
\let\labelindent\relax
\usepackage{enumitem}
\usepackage{mdwlist}
\usepackage{textcomp}
\usepackage{siunitx}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{bbm}


\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

\allowdisplaybreaks

\newtheorem{theorem}{Theorem}

\newcommand{\figref}[1]{Fig.~\ref{#1}}
\newcommand{\figsubref}[1]{\subref{#1}}
\newcommand{\tabref}[1]{Table~\ref{#1}}
\newcommand{\tabsubref}[1]{Table~\subref{#1}}
\newcommand{\secref}[1]{Sec.~\ref{#1}}
\newcommand{\equref}[1]{Eq.~(\ref{#1})}
\newcommand{\appref}[1]{(App.~\ref{#1})}
\renewcommand{\algref}[1]{Alg.~\ref{#1}}
\newcommand{\theoremref}[1]{Theorem~\ref{#1}}

\newcommand{\etal}{\emph{et~al.}\xspace}
\newcommand{\eg}{\emph{e.g.},\xspace}
\newcommand{\ie}{\emph{i.e.},\xspace}
\newcommand{\etc}{etc.\xspace}
\newcommand{\cf}{\emph{cf.}\xspace}

\newcommand{\highlight}[1]{\textit{#1}}
\newcommand\fakeparagraph[1]{\par\noindent\textbf{{#1}}.\xspace}
\newcommand\fakeparagraphnodot[1]{\par\noindent\textbf{{#1}}\xspace}
\newcommand\circled[1]{\textcircled{\small{#1}}}

\newcommand{\aucroc}{AUC-ROC\xspace}

\usepackage{color}
\newcommand{\olga}[1]{{\color{red} Olga: #1}}
\newcommand{\rahim}[1]{{\color{blue} Rahim: #1}}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage{hyperref}
\usepackage{url}


\title{Generalization}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{Rahim Entezari}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

%\iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
Since September 2019, I was reading about Robustness+ Network Compression. The more I am reading, the more I get that there is a strong correlation between robustness/stability, generalization, generalization bounds, and compression. I found some interesting papers and talks regarding this and I will cover them here.
\end{abstract}

\section{Generalization and compression}
The whole story starts with \figref{generalization_mystery} . While we expect that with more parameters in model we have less generalization, in Deep Neural Network it is not the case.

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.5\columnwidth]{pix/ICML2019Slides.png}
\caption{Generalizaion gets better with overparametrized deep neural networks(~\cite{arora2018stronger})}
\end{center}
\label{generalization_mystery}
\end{figure}

Guiding Q: Why is it a good idea to train VGG19 (20M parameters) on CIFAR 10?\\In order to solve this mystery we might have a look on generalization bounds in ML:
\begin{equation}
	error_{test} \leq error_{training} + c \sqrt{\frac{capacity}{m}}
\label{gen_ml}
\end{equation}
In which, the capacity roughly corresponds to the number of parameters and m is the number of training samples.
However \eqref{gen_ml} is not working for DL because the number of params are way more than m(very loose bound). Many other bounds proposed but their common problem is that they are way more than number of params.

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.5\columnwidth]{pix/NormbasedGenBounds.png}
\caption{Norm based generalization bounds are loose, alot more than number of parameters (~\cite{arora2018stronger})}
\end{center}
\label{generalization_mystery}
\end{figure}
~\cite{arora2018stronger} tries to answer this question: What property of network trained on real data can help to sharpen this bound? They defined \textbf{noise stability} of trained neural network: How injected gaussian noise at a layer affects higher layers? \ie noise propagation in layers. Noise stability ~\cite{aroraicml18}: add gaussian $\eta$ to output x of a layer ($|\eta| = |x|$), then measure change in higher layers, if small then network is \textbf{noise stable}.
\begin{figure}[h]
\begin{center}
\includegraphics[width=0.8\columnwidth]{pix/VGGNoiceInjection.png}
\caption{Attenuation of injected noise on a VGG-19 net trained on CIFAR-10. The x-axis is the index of layers and y-axis denote the relative error due to the noise $(\frac{\left \| \hat{x}^i-x^i \right \|_2}{\left \|x^i \right \|_2})$. A curve starts at the layer where a scaled Gaussian noise is injected to its input, whose $l_2$ norm is set to 10\% of the norm of its original input. As it propagates up, the injected noise has rapidly decreasing effect on higher layers, i.e. The injected noise to higher layers get attenuated very much. This property is shown to imply compressibility (~\cite{arora2018stronger})}
\end{center}
\label{VGGnoiseinjection}
\end{figure}
They injected gaussian noise into VGG. Fig \figref{VGGnoiseinjection} shows the result. Even for larger noise, i.e. close to the original signal, the factor of the noise is disappearing. They emprically found that noise stability correlates strongly with generalization error during training.
\fakeparagraph{noise stability to bound effective capacity} How do trained nets achieve noise stability? What does it have to do with generalization? They propose that when we prune the network we inject noise to the model.
\begin{itemize}
\item noise stability of one layer~\cite{aroraicml18}: Assume that there is no nonlinearity, \ie fully connected layer (Matrix weight M). This layer is noise stable iff $(\frac{|Mx|}{|x|} \gg \frac{|M\eta|}{|\eta|})$. \\
What does this mean mathematically? $\frac{|Mx|}{|x|}$ is uppber bounded by the \textbf{top (larger) singular values}  of matrix M, so $\frac{|Mx|}{|x|}\geq \sigma_{max}(M)$. As the gaussian noise is evenly distriuted in all directions, \eg singular directions, a simple calculation shows that the right term is related to the \textbf{$l_2$ norm of singular values} , \ie $\frac{|M\eta|}{|\eta|}) = \frac{\sqrt{\sum_{i} \sigma_i(M)^2}}{\sqrt{n}}$. This suggests that the singular values are concentrated. As \figref{SVdistrubition_vgg} shows, there are few large singular values, and most of them (thousands) are close to zero. These are close to zero, but exactly zero, so they may contribute to the norm, but they are very few large singular values. Dicrading such small values is not a good idea.

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.3\columnwidth]{pix/SVdistributionVGG.png}
\caption{Distribution of singular values in a filter of layer 10 of VGG19. Such matrices are \textbf{compressible}(~\cite{aroraicml18})}
\end{center}
\label{SVdistrubition_vgg}
\end{figure}

They propose a new compression method, in which at the end number of parameters $\ll$ number of data points (before compression, number of parameters $\gg$ number of data points). Important: compression method allowed to use any number of new random bits, provided they do not depend on data.\\ 
proof sketch : noise stanility $\rightarrow$ deep net compressible with minimal change to training error.
\begin{itemize}
\item idea 1: \textbf{Compress} a layer(randomized in such a way that error introduced are "Gaussian like"). Compression algorithm is like Random Linear Projection, where we take the projection of layer matrix on to these sign matrices (Nontrivial extension to convolutional nets).
\item  Errors (gaussian noise) \textbf{attenuate} as they go through network, as noted earlier.
\end{itemize}

\begin{algorithm}[h]
\caption{Compression }
\label{alg:LT}
\begin{algorithmic}[1]
\State Generate $K$ random sign matrices $M_1, ..., M_k$ (important: picked before seeing the data)
\State $\hat{A} = \dfrac{1}{k}\sum_{i}^{k}<A,M_t>M_t$
\end{algorithmic}
\end{algorithm}

\end{itemize}
\fakeparagraph{The Quantitatie Bound} we can measure the below definitions on the desired network, and this gives us an upper bound on the capacity of such network. These are the properties that allow noise stability.
\begin{equation}
  \label{eq:capacity_compression}
	capacity \approx (\frac{depth \times activation contraction}{layer cushion \times interlayer cushion})^2,
\end{equation}

\fakeparagraph{The Qulitatie Check} Correlation with Generalization.
\begin{figure}[h]
\begin{center}
\includegraphics[width=0.6\columnwidth]{pix/QualitativeCheck.png}
\caption{}
\end{center}
\label{QualitativeCheck}
\end{figure}
\fakeparagraph{The Qulitatie Check} Correlation with Generalization.
\begin{figure}[h]
\begin{center}
\includegraphics[width=0.7\columnwidth]{pix/CorrelationtoGeneralization.png}
\caption{Correlation with Generalization}
\end{center}
\label{QualitativeCheck}
\end{figure}



















\bibliography{iclr2020_conference}
\bibliographystyle{iclr2020_conference}

\appendix
\section{Appendix}
You may include other additional sections here. 

\end{document}
